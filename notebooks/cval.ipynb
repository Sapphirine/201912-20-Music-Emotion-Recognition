{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Performance of our MER System\n",
    "\n",
    "Our system uses the audio features of a song to predict the empirical PDF of a song in the valence/arousal space. We'll evaluate how accurately we are able to predict these PDFs by comparing them to the actual PDFs which were obtained using kernel density estimation of point-level valence/arousal data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from mer.learn_kde_audio import map_factor_learn, emotion_space_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "\n",
    "1. Audio Feature Data\n",
    "2. Empirical PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd().parent / 'data' / 'final'\n",
    "\n",
    "audio_df = pd.read_csv(data_path / 'audio_feature_71_train.csv', index_col=0) \\\n",
    "    .sort_index() \\\n",
    "    .values\n",
    "pdf_df = pd.read_csv(data_path / 'Time_Average_Gamma_0_1.csv', index_col='song_id') \\\n",
    "    .sort_index() \\\n",
    "    .values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 71)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 256)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Performance with Cross-Validation\n",
    "\n",
    "We'll use 5-fold cross validation and our performance metric will be the coefficient of determination $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(x, y):\n",
    "    \"\"\"returns the coefficient of determination\"\"\"\n",
    "    return np.corrcoef(x, y)[0, 1] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hold-Out Cross Validation\n",
    "\n",
    "This method was not used in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hold-out cross-validation\n",
    "\n",
    "r2_vals = []\n",
    "for i in range(len(audio_df)):\n",
    "    audio_test, pdf_test = audio_df[i, :], pdf_df[i, :]\n",
    "    audio_train, pdf_train = np.delete(audio_df, i, 0), np.delete(pdf_df, i, 0)\n",
    "    \n",
    "    map_factors = map_factor_learn(audio_train, audio_test)\n",
    "#     print(audio_train.shape)\n",
    "#     print(map_factors.shape)\n",
    "#     print(pdf_train.shape)\n",
    "    pred_pdf = emotion_space_map(pdf_train, map_factors)\n",
    "    \n",
    "    r2_vals.append(r_squared(pdf_test, pred_pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R^2: 0.7494501060727498\n",
      "Standard Deviation R^2: 0.22781594703318286\n"
     ]
    }
   ],
   "source": [
    "print('Mean R^2: {}\\n\\\n",
    "Standard Deviation R^2: {}'.format(np.mean(r2_vals), np.std(r2_vals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Fold Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_5fold = []\n",
    "for train_index, test_index in kf.split(audio_df):\n",
    "    audio_train, audio_test = audio_df[train_index], audio_df[test_index]\n",
    "    pdf_train, pdf_test = pdf_df[train_index], pdf_df[test_index]\n",
    "    for song_audio in audio_test:\n",
    "        map_factors = map_factor_learn(audio_train, song_audio)\n",
    "        new_pdf = emotion_space_map(pdf_train, map_factors)\n",
    "        r2_5fold.append(r_squared(pdf_test, pred_pdf))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R^2: 0.3778321825343548\n",
      "Standard Deviation R^2: 0.33401046758544595\n"
     ]
    }
   ],
   "source": [
    "print('Mean R^2: {}\\n\\\n",
    "Standard Deviation R^2: {}'.format(np.mean(r2_5fold), np.std(r2_5fold)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
